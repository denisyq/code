框架有很多，hadoop, spark, storm
基本底层都是HDFS的文件系统管理数据，中间跑hadoop/Spark/Storm，每个框架针对性不同，再上面是Hive/Pig
Pig是接近脚本方式去描述MapReduce，Hive则用的是SQL。或者HDFS上直接跑Impala，Drill，Presto。这解决了中低速数据处理的要求。

Storm是最流行的流计算平台。流计算的思路是，如果要达到更实时的更新，我何不在数据流进来的时候就处理了？比如还是词频统计的例子，我的数据流是一个一个的词，我就让他们一边流过我就一边开始统计了。流计算很牛逼，基本无延迟，但是它的短处是，不灵活，你想要统计的东西必须预先知道，毕竟数据流过就没了，你没算的东西就无法补算了.

大数据的论文基础是google发布的MapReduce/FS/BigTable

除此之外，还有一些更特制的系统／组件，比如
Mahout是分布式机器学习库，
Protobuf是数据交换的编码和库，
ZooKeeper是高一致性的分布存取协同系统，等等。 有了这么多乱七八糟的工具，都在同一个集群上运转，大家需要互相尊重有序工作。所以另外一个重要组件是，调度系统。现在最流行的是
Yarn。你可以把他看作中央管理.

=====================
HDFS
NameNode 相当于控制器，每个user的数据访问请求，都是给他的。然后他再告诉user去哪里拿数据。
DataNode 实际储存数据的地方，一般有三个备份，备份信息是NameNode保存。DataNode每隔一段时间3s给自己的NameNode发送心跳。如果10分钟NameNode没有收到自己管理的DataNode发送的心跳，则认为DataNode数据丢失，可能是断电重启等原因。这个时候NameNode要求启动一个进程去处理，并查看自己的备份，是否满足3个备份数量。如果不满足，则继续要求增加备份直到备份数量符合要求。这样，分布式文件系统中，丢失一个节点的数据，并不影响整体数据安全。
DataNode 存储的数据 按照128M为单位Block，数据按照最大的Block Size切分。同时保证一起存储三个备份即三个位置。三个备份如何选择？第一个备份，放在写入方相当的机架里，另外两个备份放在不同的机架上。相同的机架类似本地，无网络链接等等错误。

